{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75a6c5ab",
   "metadata": {},
   "source": [
    "## Running OWL2Vec*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2658935d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "* Owlready2 * Warning: optimized Cython parser module 'owlready2_optimized' is not available, defaulting to slower Python implementation\n",
      "[nltk_data] Downloading package punkt to /home/ernesto/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "INFO: Access the ontology ...\n",
      "INFO: There are 1945 triples in the ontology\n",
      "INFO: Calculate the ontology projection ...\n",
      "INFO: Creating ontology graph projection...\n",
      "INFO: \tExtracting subsumption triples\n",
      "INFO: \t\tTime extracting subsumption: 0.9801535606384277 seconds \n",
      "INFO: \tExtracting equivalence triples\n",
      "INFO: \t\tTime extracting equivalences: 0.02132725715637207 seconds \n",
      "INFO: \tExtracting class membership triples.\n",
      "INFO: \t\tTime extracting class membership: 0.3026866912841797 seconds \n",
      "INFO: \tExtracting sameAs triples\n",
      "INFO: \t\tTime extracting sameAs: 0.007425546646118164 seconds \n",
      "INFO: \tExtracting triples associated to hasBase\n",
      "INFO: \t\tTime extracting triples for property: 0.16327238082885742 seconds \n",
      "INFO: \tExtracting triples associated to hasIngredient\n",
      "INFO: \t\tTime extracting triples for property: 0.11846089363098145 seconds \n",
      "INFO: \tExtracting triples associated to isBaseOf\n",
      "INFO: \t\tTime extracting triples for property: 0.11457180976867676 seconds \n",
      "INFO: \tExtracting triples associated to hasCountryOfOrigin\n",
      "INFO: \t\tTime extracting triples for property: 0.10942578315734863 seconds \n",
      "INFO: \tExtracting triples associated to isIngredientOf\n",
      "INFO: \t\tTime extracting triples for property: 0.10830497741699219 seconds \n",
      "INFO: \tExtracting triples associated to hasSpiciness\n",
      "INFO: \t\tTime extracting triples for property: 0.12644720077514648 seconds \n",
      "INFO: \tExtracting triples associated to hasTopping\n",
      "INFO: \t\tTime extracting triples for property: 0.18382811546325684 seconds \n",
      "INFO: \tExtracting triples associated to isToppingOf\n",
      "INFO: \t\tTime extracting triples for property: 0.11280679702758789 seconds \n",
      "INFO: \tExtracting data property assertions\n",
      "INFO: \t\tTime extracting data property assertions: 0.0008273124694824219 seconds \n",
      "INFO: \tExtracting complex equivalence axioms\n",
      "INFO: \t\tTime extracting complex equivalence axioms: 3.579852342605591 seconds \n",
      "INFO: \tExtracting annotations.\n",
      "INFO: \t\tTime extracting annotations: 0.5293996334075928 seconds \n",
      "INFO: Projection created into a Graph object (RDFlib library)\n",
      "INFO: Projection saved into turtle file: ./cache/projection.ttl\n",
      "INFO: Extract classes and individuals ...\n",
      "INFO: Extract axioms ...\n",
      "INFO: Extract annotations ...\n",
      "INFO: Generate URI document ...\n",
      "INFO: Extracted 3350 walks for 104 seed entities\n",
      "INFO: Extracted 279 axiom sentences\n",
      "INFO: Generate literal document ...\n",
      "INFO: Extracted 34 annotation sentences\n",
      "INFO: Generate mixture document ...\n",
      "INFO: URI_Doc: 3629, Lit_Doc: 12069, Mix_Doc: 3629\n",
      "INFO: Time for document construction: 8.187278985977173 seconds\n",
      "INFO: Train the language model ...\n",
      "INFO: collecting all words and their counts\n",
      "INFO: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO: PROGRESS: at sentence #10000, processed 58512 words, keeping 637 word types\n",
      "INFO: collected 784 word types from a corpus of 112873 raw words and 19327 sentences\n",
      "INFO: Creating a fresh vocabulary\n",
      "INFO: Word2Vec lifecycle event {'msg': 'effective_min_count=1 retains 784 unique words (100.00% of original 784, drops 0)', 'datetime': '2023-03-24T22:10:24.036062', 'gensim': '4.3.1', 'python': '3.8.10 (default, Mar 13 2023, 10:26:41) \\n[GCC 9.4.0]', 'platform': 'Linux-5.4.0-144-generic-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}\n",
      "INFO: Word2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 112873 word corpus (100.00% of original 112873, drops 0)', 'datetime': '2023-03-24T22:10:24.036779', 'gensim': '4.3.1', 'python': '3.8.10 (default, Mar 13 2023, 10:26:41) \\n[GCC 9.4.0]', 'platform': 'Linux-5.4.0-144-generic-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}\n",
      "INFO: deleting the raw counts dictionary of 784 items\n",
      "INFO: sample=0.001 downsamples 57 most-common words\n",
      "INFO: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 53002.88510103317 word corpus (47.0%% of prior 112873)', 'datetime': '2023-03-24T22:10:24.045171', 'gensim': '4.3.1', 'python': '3.8.10 (default, Mar 13 2023, 10:26:41) \\n[GCC 9.4.0]', 'platform': 'Linux-5.4.0-144-generic-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}\n",
      "INFO: estimated required memory for 784 words and 100 dimensions: 1019200 bytes\n",
      "INFO: resetting layer weights\n",
      "INFO: Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-03-24T22:10:24.054369', 'gensim': '4.3.1', 'python': '3.8.10 (default, Mar 13 2023, 10:26:41) \\n[GCC 9.4.0]', 'platform': 'Linux-5.4.0-144-generic-x86_64-with-glibc2.29', 'event': 'build_vocab'}\n",
      "INFO: Word2Vec lifecycle event {'msg': 'training model with 4 workers on 784 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=25 window=5 shrink_windows=True', 'datetime': '2023-03-24T22:10:24.055253', 'gensim': '4.3.1', 'python': '3.8.10 (default, Mar 13 2023, 10:26:41) \\n[GCC 9.4.0]', 'platform': 'Linux-5.4.0-144-generic-x86_64-with-glibc2.29', 'event': 'train'}\n",
      "INFO: EPOCH 0: training on 112873 raw words (52938 effective words) took 0.2s, 312469 effective words/s\n",
      "INFO: EPOCH 1: training on 112873 raw words (53039 effective words) took 0.2s, 331347 effective words/s\n",
      "INFO: EPOCH 2: training on 112873 raw words (53213 effective words) took 0.2s, 340415 effective words/s\n",
      "INFO: EPOCH 3: training on 112873 raw words (52979 effective words) took 0.2s, 343201 effective words/s\n",
      "INFO: EPOCH 4: training on 112873 raw words (52995 effective words) took 0.2s, 310423 effective words/s\n",
      "INFO: EPOCH 5: training on 112873 raw words (53063 effective words) took 0.2s, 300268 effective words/s\n",
      "INFO: EPOCH 6: training on 112873 raw words (52935 effective words) took 0.2s, 347723 effective words/s\n",
      "INFO: EPOCH 7: training on 112873 raw words (52999 effective words) took 0.2s, 342353 effective words/s\n",
      "INFO: EPOCH 8: training on 112873 raw words (53079 effective words) took 0.2s, 327385 effective words/s\n",
      "INFO: EPOCH 9: training on 112873 raw words (53002 effective words) took 0.2s, 343187 effective words/s\n",
      "INFO: Word2Vec lifecycle event {'msg': 'training on 1128730 raw words (530242 effective words) took 1.7s, 310157 effective words/s', 'datetime': '2023-03-24T22:10:25.766244', 'gensim': '4.3.1', 'python': '3.8.10 (default, Mar 13 2023, 10:26:41) \\n[GCC 9.4.0]', 'platform': 'Linux-5.4.0-144-generic-x86_64-with-glibc2.29', 'event': 'train'}\n",
      "INFO: Word2Vec lifecycle event {'params': 'Word2Vec<vocab=784, vector_size=100, alpha=0.025>', 'datetime': '2023-03-24T22:10:25.766733', 'gensim': '4.3.1', 'python': '3.8.10 (default, Mar 13 2023, 10:26:41) \\n[GCC 9.4.0]', 'platform': 'Linux-5.4.0-144-generic-x86_64-with-glibc2.29', 'event': 'created'}\n",
      "INFO: Time for learning the language model: 1.7663099765777588 seconds\n",
      "INFO: Word2Vec lifecycle event {'fname_or_handle': './cache/output/ontology.embeddings', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-03-24T22:10:25.772023', 'gensim': '4.3.1', 'python': '3.8.10 (default, Mar 13 2023, 10:26:41) \\n[GCC 9.4.0]', 'platform': 'Linux-5.4.0-144-generic-x86_64-with-glibc2.29', 'event': 'saving'}\n",
      "INFO: not storing attribute cum_table\n",
      "INFO: saved ./cache/output/ontology.embeddings\n",
      "INFO: storing 784x100 projection weights into ./cache/output/ontology.embeddings.txt\n"
     ]
    }
   ],
   "source": [
    "from owl2vec_star import owl2vec_star\n",
    "\n",
    "\n",
    "#Parameters:\n",
    "# ontology_file\n",
    "# config_file\n",
    "# uri_doc\n",
    "# lit_doc\n",
    "# mix_doc\n",
    "gensim_model = owl2vec_star.extract_owl2vec_model(\"./case_studies/pizza/pizza.owl\", \"./default.cfg\", True, True, True)\n",
    "\n",
    "output_folder=\"./cache/output/\"\n",
    "\n",
    "#Gensim format\n",
    "gensim_model.save(output_folder+\"ontology.embeddings\")\n",
    "    #Txt format\n",
    "gensim_model.wv.save_word2vec_format(output_folder+\"ontology.embeddings.txt\", binary=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a78df2",
   "metadata": {},
   "source": [
    "## Loading embeddings and getting similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fdbcf09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: loading KeyedVectors object from ./cache/output/ontology.embeddings\n",
      "INFO: loading wv recursively from ./cache/output/ontology.embeddings.wv.* with mmap=r\n",
      "INFO: setting ignored attribute cum_table to None\n",
      "INFO: Word2Vec lifecycle event {'fname': './cache/output/ontology.embeddings', 'datetime': '2023-03-24T22:10:31.468587', 'gensim': '4.3.1', 'python': '3.8.10 (default, Mar 13 2023, 10:26:41) \\n[GCC 9.4.0]', 'platform': 'Linux-5.4.0-144-generic-x86_64-with-glibc2.29', 'event': 'loaded'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector for 'pizza'\n",
      "[-0.04805578  0.36815825  0.27720055  0.33223763  0.08338034  0.20342226\n",
      " -0.3855777  -0.15320176 -0.02280917 -0.03937851 -0.26031592  0.47582552\n",
      "  0.07132504 -0.06148202 -0.17438169 -0.00636079  0.14588173 -0.63705957\n",
      "  0.02384941  0.20748928  0.00259547  0.33341962 -0.0549612  -0.06585405\n",
      "  0.2768638  -0.20236917  0.41706467  0.28647998 -0.1789005   0.52457213\n",
      " -0.24252151 -0.15356635 -0.19352606 -0.28733453  0.24673043 -0.3015947\n",
      "  0.37758917  0.02215663 -0.46165714 -0.15647025 -0.1395751  -0.12670076\n",
      " -0.02626577 -0.23824978 -0.08009773 -0.33615997 -0.28883043  0.34714925\n",
      "  0.43300802 -0.7463461   0.42942187  0.11704659 -0.15203488 -0.3481388\n",
      "  0.6040846  -0.06067863 -0.25035346  0.07814031  0.11420344 -0.08409557\n",
      "  0.87211967  0.3620162  -0.60607076  0.24686007  0.07521977  0.4600163\n",
      " -0.19330214  0.05407934 -0.22347635 -0.02440841 -0.18860283 -0.259282\n",
      " -0.24300312 -0.13661171 -0.24916683  0.08750533  0.6640286  -0.26419458\n",
      " -0.00637082 -0.78845793 -0.4753987   0.06327657 -0.5574702   0.15884453\n",
      " -0.44192982  0.40995607 -0.6166017  -0.24132709  0.05479579  0.20844479\n",
      "  0.8880459   0.5032983   0.4159221   0.03608     0.25265422 -0.14511608\n",
      " -0.11116973  0.24985303 -0.01814649 -0.24598742]\n",
      "0.48213938\n",
      "0.7549434\n",
      "[('rosa pizza', 0.8038203120231628), ('margherita pizza', 0.8003750443458557), ('caprina pizza', 0.7873907089233398), ('mushroom pizza', 0.7811030149459839), ('parmese pizza', 0.7729876637458801), ('napoletana pizza', 0.7701953053474426), ('prince carlo pizza', 0.7617061734199524), ('american pizza', 0.7566004991531372), ('la reine pizza', 0.7563369274139404), ('sundried tomato', 0.7546383142471313)]\n",
      "[('unclosedpizza', 0.9060808420181274), ('unclosed', 0.8975483775138855), ('margherita pizza', 0.8824741840362549), ('rosa pizza', 0.882378101348877), ('http://www.co-ode.org/ontologies/pizza/pizza.owl#Margherita', 0.877470850944519), ('caprina pizza', 0.8765340447425842), ('mushroom pizza', 0.8731290102005005), ('parmese pizza', 0.8632004857063293), ('sundried tomato', 0.861819863319397), ('napoletana pizza', 0.8605837821960449)]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "#Embedding vectors generated above\n",
    "model = KeyedVectors.load(\"./cache/output/ontology.embeddings\", mmap='r')\n",
    "wv = model.wv\n",
    "\n",
    "vector = wv['pizza']  # Get numpy vector of a word\n",
    "print(\"Vector for 'pizza'\")\n",
    "print(vector)\n",
    "\n",
    "#cosine similarity\n",
    "similarity = wv.similarity('pizza', 'http://www.co-ode.org/ontologies/pizza/pizza.owl#Pizza')\n",
    "print(similarity)\n",
    "\n",
    "similarity = wv.similarity('http://www.co-ode.org/ontologies/pizza/pizza.owl#Margherita', 'margherita')\n",
    "print(similarity)\n",
    "\n",
    "\n",
    "#Most similar cosine similarity\n",
    "result = wv.most_similar(positive=['margherita', 'pizza'])\n",
    "print(result)\n",
    "\n",
    "#Most similar entities: cosmul\n",
    "result = wv.most_similar_cosmul(positive=['margherita'])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cdbe3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
